{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using simcat for network inference\n",
    "## Three-step process: \n",
    "1) Training database simulation  \n",
    "2) Model training  \n",
    "3) Model application  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Training database simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipcoal\n",
    "import toytree\n",
    "import simcat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in your species tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assume we already have a newick\n",
    "newick = '(beebalm:8.57143e+06,(whale_shark:7.14286e+06,(coelacanth:5.71429e+06,(spotted_salamander:4.28571e+06,(hamster:2.85714e+06,(dragon:1.42857e+06,kinglet:1.42857e+06)0:1.42857e+06)0:1.42857e+06)0:1.42857e+06)0:1.42857e+06)0:1.42857e+06);'\n",
    "newick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to toytree format\n",
    "tree = toytree.tree(newick)\n",
    "\n",
    "# look at it\n",
    "tree.draw();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each edge is named by its tip-ward node number.\n",
    "tree.draw(node_labels='idx',\n",
    "          node_sizes=15,\n",
    "          tip_labels=['0','1','2','3','4','5','6']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use simcat to automatically construct an empty database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of the tutorial we will make the training database small -- just 500 simulations with 5000 SNPs each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = simcat.Database(\"tutorial\",\n",
    "                'tutorial_data/',\n",
    "                tree,\n",
    "                nrows=500,\n",
    "                nsnps=5000,\n",
    "                Ne_min=10000, # how much should Ne vary on the branches?\n",
    "                Ne_max=50000,\n",
    "                admix_prop_min=0.3, # how much should the magnitude of admixture event vary?\n",
    "                admix_prop_max=0.5,\n",
    "                admix_edge_min=0.5, # how much should the timing of admixture event vary?\n",
    "                admix_edge_max=0.5,\n",
    "                exclude_sisters=True, # do we want to include introgression between sister taxa?\n",
    "                node_slide_prop=0.1, # how much do we want internal nodes to shift around?\n",
    "                existing_admix_edges=[],) # do we want to assume any existing edges?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the empty database with simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simulator = simcat.Simulator(\"tutorial\",\"tutorial_data/\")  # inits the simulator\n",
    "simulator.run(500,auto=True) # runs as many simulations as we specify, automatically detects available cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training automation\n",
    "from simcat import BatchTrain\n",
    "# for defining the model\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the parameters for training:\n",
    "\n",
    "* Where is the data?\n",
    "* What do want to name the outputs?\n",
    "* What proportion do we want to split into training vs. testing?\n",
    "* Do we want to exclude scenarios with introgression between sister taxa?\n",
    "* Do we want to exclude scenarios where introgression is really low?\n",
    "* Do we want to make a \"zero\" category that includes all remaining simulations with magnitude under some number?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_model = BatchTrain(input_name='tutorial', # use the name of the training database\n",
    "                    output_name='tutorial_model', # this is the name for model-related files\n",
    "                    directory='tutorial_data/', # point to the same directory as training database\n",
    "                    prop_training=0.9, # how much of the data should be used for training (vs testing)?\n",
    "                    exclude_sisters=True, # do we want to exclude any sister-taxon introgression scenarios?\n",
    "                    exclude_magnitude=0.1, # do we want to exclude events below a certain magnitude?\n",
    "                    to_zero_magnitude=0, # do we want to label events below a certain magnitude as \"zero\"?\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An \"analysis.h5\" file has been saved as output. It contains indices for simulations in the training vs testing dataset, as well as some metadata about the training. \n",
    "#### A \"onehot_dict.csv\" file has also been saved, to convert between integer codes and the literal string labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture defined with Keras tools\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=tutorial_model.input_shape, activation='relu'))\n",
    "model.add(Dense(tutorial_model.num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the network model for the BatchTrain object -- which will also save the model as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_model.init_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now designate the batch size and the number of epochs, and train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tutorial_model.train(batch_size=10,\n",
    "             num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model is automatically saved to disk after each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We would normally have empicial data -- but here we will simulate some sequence data with introgression from branch 0 to branch 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod = ipcoal.Model(tree,admixture_edges=[(0,3,.5,.4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate an alignment of 5000 SNPs\n",
    "dat_mod.sim_snps(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is our SNP alignment -- an array of (ntaxa x nsnps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_mod.seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the rows of the SNP alignment correspond to the alphanumeric ordering of the tree's tip names\n",
    "dat_mod.alpha_ordered_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the object once again, but indicate that it already exists\n",
    "tutorial_model = BatchTrain(input_name='tutorial',\n",
    "                    output_name='tutorial_model',\n",
    "                    directory='tutorial_data/',\n",
    "                    exists=True, # specifies that the saved model already exists\n",
    "                   )\n",
    "# load the keras model into the object\n",
    "tutorial_model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pass our sequence data to the model to get a prediction\n",
    "tutorial_model.pass_alignment_to_model(dat_mod.seqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
